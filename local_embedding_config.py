# -*- coding: utf-8 -*-
"""
æœ¬åœ°Hugging Faceæ¨¡å‹é…ç½®
æ”¯æŒç¦»çº¿ä½¿ç”¨sentence-transformers/all-MiniLM-L6-v2æ¨¡å‹
"""

import os

# æœ¬åœ°æ¨¡å‹é…ç½®
LOCAL_EMBEDDING_CONFIG = {
    # æ¨¡å‹åŸºæœ¬ä¿¡æ¯
    'model_name': 'sentence-transformers/all-MiniLM-L6-v2',
    'snapshot_id': 'c9745ed1d9f207416be6d2e6f8de32d1f16199bf',
    
    # ç¼“å­˜è·¯å¾„é…ç½®
    'cache_dir': os.path.expanduser("~/.cache/huggingface/hub"),
    
    # ç¦»çº¿æ¨¡å¼è®¾ç½®
    'force_offline': True,
    'use_local_only': True,
}

def setup_offline_mode():
    """è®¾ç½®ç¦»çº¿æ¨¡å¼ç¯å¢ƒå˜é‡"""
    if LOCAL_EMBEDDING_CONFIG['force_offline']:
        os.environ['HF_HUB_OFFLINE'] = '1'
        os.environ['TRANSFORMERS_OFFLINE'] = '1'
        print("âœ“ å·²å¯ç”¨Hugging Faceç¦»çº¿æ¨¡å¼")

def get_local_model_path():
    """è·å–æœ¬åœ°æ¨¡å‹å®Œæ•´è·¯å¾„"""
    model_name = LOCAL_EMBEDDING_CONFIG['model_name']
    snapshot_id = LOCAL_EMBEDDING_CONFIG['snapshot_id']
    cache_dir = LOCAL_EMBEDDING_CONFIG['cache_dir']
    
    # æ„å»ºæ ‡å‡†Hugging Faceç¼“å­˜è·¯å¾„
    model_cache_name = model_name.replace('/', '--')
    local_path = os.path.join(
        cache_dir,
        f"models--{model_cache_name}",
        "snapshots",
        snapshot_id
    )
    
    return local_path

def load_local_embedding_model():
    """åŠ è½½æœ¬åœ°åµŒå…¥æ¨¡å‹"""
    try:
        from sentence_transformers import SentenceTransformer
        
        # è®¾ç½®ç¦»çº¿æ¨¡å¼
        setup_offline_mode()
        
        model_name = LOCAL_EMBEDDING_CONFIG['model_name']
        cache_dir = LOCAL_EMBEDDING_CONFIG['cache_dir']
        local_path = get_local_model_path()
        
        print(f"æ­£åœ¨åŠ è½½æœ¬åœ°åµŒå…¥æ¨¡å‹: {model_name}")
        
        # å°è¯•å¤šç§åŠ è½½æ–¹å¼
        loading_methods = [
            # æ–¹æ³•1: ç›´æ¥ä½¿ç”¨æœ¬åœ°è·¯å¾„
            ('ç›´æ¥è·¯å¾„', lambda: SentenceTransformer(local_path)),
            
            # æ–¹æ³•2: ä½¿ç”¨æ¨¡å‹åç§° + ç¼“å­˜ç›®å½•
            ('æ¨¡å‹åç§°+ç¼“å­˜', lambda: SentenceTransformer(model_name, cache_folder=cache_dir)),
            
            # æ–¹æ³•3: ä»…ä½¿ç”¨æ¨¡å‹åç§°ï¼ˆä¾èµ–ç¯å¢ƒå˜é‡ï¼‰
            ('æ¨¡å‹åç§°', lambda: SentenceTransformer(model_name)),
        ]
        
        for method_name, loader in loading_methods:
            try:
                print(f"å°è¯•åŠ è½½æ–¹æ³•: {method_name}")
                
                # å¯¹äºç›´æ¥è·¯å¾„æ–¹æ³•ï¼Œå…ˆæ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
                if method_name == 'ç›´æ¥è·¯å¾„' and not os.path.exists(local_path):
                    print(f"  Ã— è·¯å¾„ä¸å­˜åœ¨: {local_path}")
                    continue
                
                model = loader()
                print(f"  âœ“ æˆåŠŸä½¿ç”¨ {method_name} åŠ è½½æ¨¡å‹")
                
                # ç®€å•æµ‹è¯•
                test_embedding = model.encode("æµ‹è¯•æ–‡æœ¬")
                print(f"  âœ“ æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼Œå‘é‡ç»´åº¦: {len(test_embedding)}")
                
                return model
                
            except Exception as e:
                print(f"  Ã— {method_name} åŠ è½½å¤±è´¥: {e}")
                continue
        
        print("Ã— æ‰€æœ‰åŠ è½½æ–¹æ³•éƒ½å¤±è´¥äº†")
        return None
        
    except ImportError:
        print("Ã— sentence_transformersæœªå®‰è£…")
        return None
    except Exception as e:
        print(f"Ã— æ¨¡å‹åŠ è½½å¼‚å¸¸: {e}")
        return None

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("=== æœ¬åœ°åµŒå…¥æ¨¡å‹åŠ è½½æµ‹è¯• ===")
    model = load_local_embedding_model()
    
    if model:
        print("\nğŸ‰ æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        
        # è¿›è¡Œä¸€äº›æµ‹è¯•
        test_texts = [
            "è¿™æ˜¯ç¬¬ä¸€ä¸ªæµ‹è¯•å¥å­",
            "è¿™æ˜¯ç¬¬äºŒä¸ªæµ‹è¯•å¥å­",
            "å®Œå…¨ä¸åŒçš„å†…å®¹"
        ]
        
        print("\n=== åµŒå…¥æµ‹è¯• ===")
        embeddings = model.encode(test_texts)
        print(f"æˆåŠŸç”Ÿæˆ {len(embeddings)} ä¸ªåµŒå…¥å‘é‡")
        print(f"æ¯ä¸ªå‘é‡ç»´åº¦: {len(embeddings[0])}")
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        from sklearn.metrics.pairwise import cosine_similarity
        import numpy as np
        
        similarity_matrix = cosine_similarity(embeddings)
        print(f"\nç›¸ä¼¼åº¦çŸ©é˜µ:")
        for i, text in enumerate(test_texts):
            print(f"{i+1}. {text}")
        print(f"\n{similarity_matrix}")
        
    else:
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥")
        print("\næ’æŸ¥å»ºè®®:")
        print("1. æ£€æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è½½åˆ°æœ¬åœ°ç¼“å­˜")
        print("2. éªŒè¯å¿«ç…§IDæ˜¯å¦æ­£ç¡®")
        print("3. ç¡®è®¤sentence-transformerså·²å®‰è£…")
        print(f"4. æ‰‹åŠ¨æ£€æŸ¥è·¯å¾„: {get_local_model_path()}")
