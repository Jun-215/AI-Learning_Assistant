#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›‘æ§RAGç³»ç»Ÿåˆå§‹åŒ–çŠ¶æ€
"""

import time
import os
import sys

print("RAGç³»ç»ŸçŠ¶æ€ç›‘æ§")
print("=" * 30)

# ç›‘æ§çŸ¥è¯†åº“åˆå§‹åŒ–
print("æ­£åœ¨ç›‘æ§ç³»ç»Ÿåˆå§‹åŒ–...")
print("æç¤º: é¦–æ¬¡åŠ è½½è¯­ä¹‰æ¨¡å‹å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ä¸‹è½½æ¨¡å‹æ–‡ä»¶")

# æ·»åŠ backendè·¯å¾„
backend_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'backend')
sys.path.insert(0, backend_dir)

start_time = time.time()
print(f"å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}")

try:
    print("\n1. å¯¼å…¥åŸºç¡€æ¨¡å—...")
    import flask
    import jieba
    import sklearn
    import numpy as np
    print("   âœ“ åŸºç¡€æ¨¡å—å¯¼å…¥å®Œæˆ")
    
    print("\n2. æ£€æŸ¥è¯­ä¹‰æœç´¢ä¾èµ–...")
    try:
        import sentence_transformers
        import faiss
        import torch
        print("   âœ“ è¯­ä¹‰æœç´¢ä¾èµ–å¯ç”¨")
        SEMANTIC_DEPS_OK = True
    except ImportError as e:
        print(f"   âœ— è¯­ä¹‰æœç´¢ä¾èµ–ç¼ºå¤±: {e}")
        SEMANTIC_DEPS_OK = False
    
    print("\n3. å¯¼å…¥åº”ç”¨æ¨¡å—...")
    from app import EMBEDDING_AVAILABLE
    print(f"   âœ“ åº”ç”¨æ¨¡å—å¯¼å…¥æˆåŠŸ")
    print(f"   åµŒå…¥åŠŸèƒ½çŠ¶æ€: {EMBEDDING_AVAILABLE}")
    
    if EMBEDDING_AVAILABLE:
        print("\n4. åˆå§‹åŒ–çŸ¥è¯†åº“ (å¯èƒ½éœ€è¦ä¸‹è½½æ¨¡å‹)...")
        print("   æ³¨æ„: é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½åµŒå…¥æ¨¡å‹ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        from app import KnowledgeBase
        kb = KnowledgeBase()
        
        elapsed = time.time() - start_time
        print(f"\nâœ“ ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
        print(f"æ€»è€—æ—¶: {elapsed:.2f} ç§’")
        
        print(f"\nç³»ç»ŸçŠ¶æ€:")
        print(f"- æ–‡æ¡£æ•°é‡: {len(kb.documents)}")
        print(f"- åµŒå…¥æ¨¡å‹: {'âœ“ å·²åŠ è½½' if kb.embedding_model else 'âœ— æœªåŠ è½½'}")
        print(f"- è¯­ä¹‰ç´¢å¼•: {'âœ“ å·²æ„å»º' if kb.embedding_index else 'âœ— æœªæ„å»º'}")
        if hasattr(kb, 'document_chunks'):
            print(f"- æ–‡æ¡£å—æ•°é‡: {len(kb.document_chunks)}")
        
        # å¿«é€Ÿæµ‹è¯•
        print(f"\n5. å¿«é€ŸåŠŸèƒ½æµ‹è¯•...")
        test_query = "äººå·¥æ™ºèƒ½"
        results = kb.search(test_query, max_results=1)
        print(f"   æŸ¥è¯¢ '{test_query}' è¿”å› {len(results)} ä¸ªç»“æœ")
        
        if results and kb.embedding_model:
            result = results[0]
            print(f"   ç»“æœæ–‡ä»¶: {result['filename']}")
            print(f"   ç›¸å…³åº¦åˆ†æ•°: {result['score']:.3f}")
            if 'semantic_score' in result:
                print(f"   è¯­ä¹‰åˆ†æ•°: {result['semantic_score']:.3f}")
        
        print(f"\nğŸ‰ RAGç³»ç»Ÿå®Œå…¨å°±ç»ª!")
        
    else:
        print(f"\nâš  è¯­ä¹‰æœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼Œç³»ç»Ÿå°†ä½¿ç”¨åŸºç¡€æœç´¢åŠŸèƒ½")
        from app import KnowledgeBase
        kb = KnowledgeBase()
        print(f"åŸºç¡€æœç´¢åŠŸèƒ½æ­£å¸¸ï¼Œæ–‡æ¡£æ•°é‡: {len(kb.documents)}")

except Exception as e:
    elapsed = time.time() - start_time
    print(f"\nâœ— ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ (è€—æ—¶: {elapsed:.2f}s)")
    print(f"é”™è¯¯: {e}")
    import traceback
    traceback.print_exc()

print(f"\nç»“æŸæ—¶é—´: {time.strftime('%H:%M:%S')}")
print("ç›‘æ§ç»“æŸ")
