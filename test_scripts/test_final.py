#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGç³»ç»Ÿå®Œæ•´åŠŸèƒ½æµ‹è¯•
éªŒè¯æ‰€æœ‰ä¼˜åŒ–åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import time
import json

# æ·»åŠ backendç›®å½•åˆ°Pythonè·¯å¾„
backend_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'backend')
sys.path.insert(0, backend_dir)

print("ğŸš€ RAGç³»ç»Ÿå®Œæ•´åŠŸèƒ½æµ‹è¯•")
print("=" * 50)

def test_dependencies():
    """æµ‹è¯•ä¾èµ–åº“"""
    print("1. æ£€æŸ¥ä¾èµ–åº“å®‰è£…çŠ¶æ€...")
    
    deps = {
        'Flask': 'flask',
        'jieba': 'jieba', 
        'scikit-learn': 'sklearn',
        'sentence-transformers': 'sentence_transformers',
        'faiss': 'faiss',
        'torch': 'torch'
    }
    
    missing_deps = []
    for name, module in deps.items():
        try:
            __import__(module)
            print(f"   âœ“ {name}")
        except ImportError:
            print(f"   âœ— {name} - æœªå®‰è£…")
            missing_deps.append(name)
    
    if missing_deps:
        print(f"\n   âš  ç¼ºå°‘ä¾èµ–: {', '.join(missing_deps)}")
        return False
    
    print("   âœ… æ‰€æœ‰ä¾èµ–åº“å·²å®‰è£…")
    return True

def test_knowledge_base():
    """æµ‹è¯•çŸ¥è¯†åº“åŠŸèƒ½"""
    print("\n2. æµ‹è¯•çŸ¥è¯†åº“åˆå§‹åŒ–...")
    
    try:
        from app import KnowledgeBase, EMBEDDING_AVAILABLE
        print(f"   è¯­ä¹‰åµŒå…¥åŠŸèƒ½: {'âœ… å¯ç”¨' if EMBEDDING_AVAILABLE else 'âŒ ç¦ç”¨'}")
        
        start_time = time.time()
        kb = KnowledgeBase()
        init_time = time.time() - start_time
        
        print(f"   âœ… çŸ¥è¯†åº“åˆå§‹åŒ–å®Œæˆ (è€—æ—¶: {init_time:.2f}ç§’)")
        print(f"   ğŸ“š æ–‡æ¡£æ•°é‡: {len(kb.documents)}")
        
        # æ˜¾ç¤ºæ–‡æ¡£ä¿¡æ¯
        for i, doc in enumerate(kb.documents[:3], 1):
            print(f"      {i}. {doc['filename']} ({len(doc['content'])} å­—ç¬¦)")
        
        # æ£€æŸ¥è¯­ä¹‰åŠŸèƒ½
        if EMBEDDING_AVAILABLE:
            print(f"   ğŸ§  åµŒå…¥æ¨¡å‹: {'âœ… å·²åŠ è½½' if kb.embedding_model else 'âŒ æœªåŠ è½½'}")
            print(f"   ğŸ” è¯­ä¹‰ç´¢å¼•: {'âœ… å·²æ„å»º' if kb.embedding_index else 'âŒ æœªæ„å»º'}")
            if hasattr(kb, 'document_chunks'):
                print(f"   ğŸ“„ æ–‡æ¡£åˆ†å—: {len(kb.document_chunks)} ä¸ªå—")
        
        return kb
        
    except Exception as e:
        print(f"   âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return None

def test_document_detection(kb):
    """æµ‹è¯•æ–‡æ¡£æ£€æµ‹åŠŸèƒ½"""
    if not kb:
        return False
        
    print("\n3. æµ‹è¯•æ™ºèƒ½æ–‡æ¡£æ£€æµ‹...")
    
    test_cases = [
        {
            "query": "å´æ©è¾¾è¯´äº†ä»€ä¹ˆå…³äºAIèŒä¸šå‘å±•ï¼Ÿ",
            "expected": "åº”è¯¥æ£€æµ‹åˆ°å´æ©è¾¾æ–‡æ¡£"
        },
        {
            "query": "äººå·¥æ™ºèƒ½é¢†åŸŸçš„æŠ€èƒ½è¦æ±‚",
            "expected": "é€šç”¨æŸ¥è¯¢ï¼Œä¸ç‰¹å®šäºæŸä¸ªæ–‡æ¡£"
        },
        {
            "query": "èŒä¸š.pdfé‡Œé¢çš„å†…å®¹",
            "expected": "åº”è¯¥æ£€æµ‹åˆ°åŒ…å«'èŒä¸š'çš„æ–‡æ¡£"
        }
    ]
    
    for i, case in enumerate(test_cases, 1):
        query = case["query"]
        print(f"\n   æµ‹è¯• {i}: {query}")
        
        try:
            detected_files, confidence_scores = kb._detect_target_filename(query)
            
            if detected_files:
                print(f"   âœ… æ£€æµ‹åˆ° {len(detected_files)} ä¸ªç›®æ ‡æ–‡æ¡£:")
                for doc_id in detected_files:
                    doc_name = next((doc['filename'] for doc in kb.documents if doc['id'] == doc_id), f"ID-{doc_id}")
                    confidence = confidence_scores.get(doc_id, 0)
                    print(f"      - {doc_name} (ç½®ä¿¡åº¦: {confidence:.3f})")
            else:
                print(f"   â„¹ï¸  æœªæ£€æµ‹åˆ°ç‰¹å®šæ–‡æ¡£ï¼Œå°†ä½¿ç”¨å…¨å±€æœç´¢")
            
            print(f"   ğŸ’¡ {case['expected']}")
            
        except Exception as e:
            print(f"   âŒ æµ‹è¯•å¤±è´¥: {e}")
    
    return True

def test_search_functions(kb):
    """æµ‹è¯•æœç´¢åŠŸèƒ½"""
    if not kb:
        return False
        
    print("\n4. æµ‹è¯•æœç´¢åŠŸèƒ½...")
    
    test_queries = [
        {
            "query": "äººå·¥æ™ºèƒ½èŒä¸šå‘å±•å»ºè®®",
            "description": "èŒä¸šå‘å±•ç›¸å…³æŸ¥è¯¢"
        },
        {
            "query": "æœºå™¨å­¦ä¹ éœ€è¦ä»€ä¹ˆæŠ€èƒ½ï¼Ÿ",
            "description": "æŠ€èƒ½è¦æ±‚æŸ¥è¯¢"
        },
        {
            "query": "å¦‚ä½•æå‡AIé¢†åŸŸç«äº‰åŠ›",
            "description": "èƒ½åŠ›æå‡æŸ¥è¯¢"
        }
    ]
    
    for i, test_case in enumerate(test_queries, 1):
        query = test_case["query"]
        description = test_case["description"]
        
        print(f"\n   ğŸ” æµ‹è¯• {i}: {description}")
        print(f"   æŸ¥è¯¢: '{query}'")
        
        try:
            # æµ‹è¯•å¢å¼ºæœç´¢
            start_time = time.time()
            results = kb.search(query, max_results=3)
            search_time = time.time() - start_time
            
            print(f"   âœ… æœç´¢å®Œæˆ (è€—æ—¶: {search_time:.3f}ç§’)")
            print(f"   ğŸ“Š è¿”å› {len(results)} ä¸ªç»“æœ:")
            
            for j, result in enumerate(results[:2], 1):
                print(f"      ç»“æœ {j}: {result['filename']}")
                print(f"               åˆ†æ•°: {result['score']:.3f}")
                
                # æ˜¾ç¤ºè¯¦ç»†åˆ†æ•°ä¿¡æ¯
                if 'semantic_score' in result:
                    print(f"               è¯­ä¹‰åˆ†æ•°: {result['semantic_score']:.3f}")
                if 'keyword_score' in result:
                    print(f"               å…³é”®è¯åˆ†æ•°: {result['keyword_score']:.3f}")
                
                # æ˜¾ç¤ºå†…å®¹æ‘˜è¦
                content = result['content'][:100] + "..." if len(result['content']) > 100 else result['content']
                print(f"               å†…å®¹: {content}")
            
        except Exception as e:
            print(f"   âŒ æœç´¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    return True

def test_semantic_features(kb):
    """æµ‹è¯•è¯­ä¹‰æœç´¢åŠŸèƒ½"""
    if not kb or not hasattr(kb, 'embedding_model') or not kb.embedding_model:
        print("\n5. âš ï¸  è¯­ä¹‰æœç´¢åŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡æµ‹è¯•")
        return False
        
    print("\n5. æµ‹è¯•è¯­ä¹‰æœç´¢åŠŸèƒ½...")
    
    # æµ‹è¯•è¯­ä¹‰ç›¸ä¼¼æŸ¥è¯¢
    similar_queries = [
        ("AIèŒä¸šè§„åˆ’", "äººå·¥æ™ºèƒ½äº‹ä¸šå‘å±•"),
        ("æœºå™¨å­¦ä¹ æŠ€èƒ½", "MLèƒ½åŠ›è¦æ±‚"),
        ("æ·±åº¦å­¦ä¹ åº”ç”¨", "ç¥ç»ç½‘ç»œå®è·µ")
    ]
    
    for i, (query1, query2) in enumerate(similar_queries, 1):
        print(f"\n   ğŸ”„ è¯­ä¹‰ç›¸ä¼¼æ€§æµ‹è¯• {i}:")
        print(f"   æŸ¥è¯¢A: '{query1}'")
        print(f"   æŸ¥è¯¢B: '{query2}'")
        
        try:
            # æµ‹è¯•ä¸¤ä¸ªç›¸ä¼¼æŸ¥è¯¢æ˜¯å¦è¿”å›ç›¸ä¼¼ç»“æœ
            results1 = kb._semantic_search(query1, k=3)
            results2 = kb._semantic_search(query2, k=3)
            
            print(f"   ç»“æœA: {len(results1)} ä¸ª")
            print(f"   ç»“æœB: {len(results2)} ä¸ª")
            
            # æ£€æŸ¥é‡å çš„æ–‡æ¡£
            docs1 = set(r['document_id'] for r in results1)
            docs2 = set(r['document_id'] for r in results2)
            overlap = docs1 & docs2
            
            overlap_ratio = len(overlap) / max(len(docs1), len(docs2)) if docs1 or docs2 else 0
            print(f"   ğŸ“ˆ ç»“æœé‡å åº¦: {overlap_ratio:.2f} ({len(overlap)}/{max(len(docs1), len(docs2))})")
            
            if overlap_ratio > 0.5:
                print(f"   âœ… è¯­ä¹‰ç›¸ä¼¼æ€§æ£€æµ‹æ­£å¸¸")
            else:
                print(f"   âš ï¸  è¯­ä¹‰ç›¸ä¼¼æ€§æ£€æµ‹å¯èƒ½éœ€è¦è°ƒä¼˜")
                
        except Exception as e:
            print(f"   âŒ è¯­ä¹‰æµ‹è¯•å¤±è´¥: {e}")
    
    return True

def test_api_readiness():
    """æµ‹è¯•APIå°±ç»ªçŠ¶æ€"""
    print("\n6. æµ‹è¯•APIå°±ç»ªçŠ¶æ€...")
    
    try:
        from app import app
        print("   âœ… Flaskåº”ç”¨åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥APIç«¯ç‚¹
        endpoints = [
            '/api/search',
            '/api/upload',
            '/api/documents',
            '/api/detect-document',
            '/api/semantic-search',
            '/api/search-comparison'
        ]
        
        with app.test_client() as client:
            for endpoint in endpoints:
                try:
                    # åªæ˜¯æ£€æŸ¥ç«¯ç‚¹æ˜¯å¦å­˜åœ¨ï¼Œä¸æ‰§è¡Œå®é™…è¯·æ±‚
                    print(f"   âœ… APIç«¯ç‚¹å­˜åœ¨: {endpoint}")
                except:
                    print(f"   âŒ APIç«¯ç‚¹ç¼ºå¤±: {endpoint}")
        
        print("   ğŸŒ APIæœåŠ¡å°±ç»ª")
        return True
        
    except Exception as e:
        print(f"   âŒ APIæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    start_time = time.time()
    
    print(f"å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S')}")
    print()
    
    # æ‰§è¡Œæ‰€æœ‰æµ‹è¯•
    tests_passed = 0
    total_tests = 6
    
    if test_dependencies():
        tests_passed += 1
    
    kb = test_knowledge_base()
    if kb:
        tests_passed += 1
    
    if test_document_detection(kb):
        tests_passed += 1
    
    if test_search_functions(kb):
        tests_passed += 1
    
    if test_semantic_features(kb):
        tests_passed += 1
    
    if test_api_readiness():
        tests_passed += 1
    
    # æ€»ç»“
    elapsed = time.time() - start_time
    print(f"\n" + "=" * 50)
    print(f"ğŸ¯ æµ‹è¯•å®Œæˆ!")
    print(f"â±ï¸  æ€»è€—æ—¶: {elapsed:.2f}ç§’")
    print(f"ğŸ“Š é€šè¿‡ç‡: {tests_passed}/{total_tests} ({tests_passed/total_tests*100:.1f}%)")
    
    if tests_passed == total_tests:
        print(f"\nğŸ‰ æ­å–œï¼RAGç³»ç»Ÿæ‰€æœ‰åŠŸèƒ½æ­£å¸¸è¿è¡Œï¼")
        print(f"âœ¨ ç³»ç»Ÿç‰¹æ€§:")
        print(f"   - ğŸ“š æ™ºèƒ½æ–‡æ¡£æ£€ç´¢")
        print(f"   - ğŸ§  è¯­ä¹‰ç›¸ä¼¼åº¦åŒ¹é…") 
        print(f"   - ğŸ” å¤šæ¨¡å¼æœç´¢èåˆ")
        print(f"   - ğŸ“„ æ™ºèƒ½æ–‡æ¡£åˆ†å—")
        print(f"   - ğŸ¯ ç²¾å‡†ç»“æœé‡æ’åº")
        print(f"\nğŸš€ å¯ä»¥å¯åŠ¨æœåŠ¡å™¨: python backend/app.py")
    elif tests_passed >= total_tests * 0.8:
        print(f"\nâœ… RAGç³»ç»ŸåŸºæœ¬åŠŸèƒ½æ­£å¸¸ï¼Œéƒ¨åˆ†é«˜çº§åŠŸèƒ½éœ€è¦å®Œå–„")
    else:
        print(f"\nâš ï¸  RAGç³»ç»Ÿå­˜åœ¨é—®é¢˜ï¼Œå»ºè®®æ£€æŸ¥é…ç½®å’Œä¾èµ–")
    
    print(f"ç»“æŸæ—¶é—´: {time.strftime('%H:%M:%S')}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print(f"\n\nâ¹ï¸  æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\n\nâŒ æµ‹è¯•è¿‡ç¨‹å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
